# MetasurfaceVIT 项目依赖关系说明

## 项目概述

MetasurfaceVIT 是一个基于 Vision Transformer 的超表面逆向设计框架。本文档详细说明了项目的模块依赖关系、数据流程和代码组织结构。

---

## 核心依赖库总览

### Python 生态系统依赖

```
MetasurfaceVIT
│
├── Python 3.8+
│   └── 基础运行环境
│
├── PyTorch 1.12+
│   ├── torch (核心深度学习框架)
│   ├── torch.nn (神经网络模块)
│   ├── torch.optim (优化器)
│   ├── torch.utils.data (数据加载)
│   └── torch.distributed (分布式训练)
│
├── CUDA 11.6+ & cuDNN 8+
│   └── GPU加速支持
│
├── timm 0.6.0+
│   ├── Transformer组件 (DropPath, LayerNorm等)
│   └── 学习率调度器 (Cosine, Step, Linear)
│
├── NumPy 1.19+
│   └── 数值计算和矩阵运算
│
├── SciPy 1.7+
│   └── interpolate (几何插值)
│
├── YACS 0.1.8+
│   └── 配置管理
│
├── Matplotlib 3.3+
│   └── 可视化
│
├── Pillow 8.0+
│   └── 图像处理
│
├── termcolor 1.1.0+
│   └── 彩色日志输出
│
└── Nvidia Apex (可选)
    └── 混合精度训练
```

### 外部工具依赖

```
Lumerical FDTD Solutions 2020 R2+
└── 用于电磁仿真
    ├── .fsp (仿真项目文件)
    └── .lsf (脚本文件)
```

---

## 模块依赖关系图

### 1. 核心架构依赖

```
┌─────────────────────────────────────────────────────────────┐
│                        Main Programs                         │
├─────────────────────────────────────────────────────────────┤
│  main_pretrain.py   main_finetune.py   main_metalens.py    │
└───────────┬─────────────────┬────────────────┬──────────────┘
            │                 │                │
            ├─────────────────┴────────────────┤
            │                                  │
    ┌───────▼────────┐              ┌─────────▼────────┐
    │  Model Module  │              │  Data Module     │
    ├────────────────┤              ├──────────────────┤
    │ - simmim.py    │              │ - data_simmim.py │
    │ - vit.py       │              │ - data_finetune.py│
    │ - __init__.py  │              │ - data_recon.py  │
    └────────┬───────┘              └─────────┬────────┘
             │                                 │
             ├─────────────────────────────────┤
             │                                 │
    ┌────────▼────────┐              ┌────────▼────────┐
    │ Training Utils  │              │ Config & Logger │
    ├─────────────────┤              ├─────────────────┤
    │ - optimizer.py  │              │ - config.py     │
    │ - lr_scheduler.py│             │ - logger.py     │
    │ - utils.py      │              │                 │
    └─────────────────┘              └─────────────────┘
```

### 2. 详细依赖关系

#### 配置层 (Configuration Layer)

```
config.py
  ├── 依赖: yacs.config.CfgNode
  ├── 被依赖:
  │   ├── main_pretrain.py
  │   ├── main_finetune.py
  │   ├── main_metalens.py
  │   ├── model/__init__.py
  │   ├── data/__init__.py
  │   ├── optimizer.py
  │   └── lr_scheduler.py
  └── 功能:
      ├── 定义所有超参数
      ├── 从预处理读取数据参数
      └── 命令行参数集成
```

#### 日志层 (Logging Layer)

```
logger.py
  ├── 依赖:
  │   ├── logging (Python标准库)
  │   └── termcolor
  ├── 被依赖:
  │   ├── main_pretrain.py
  │   ├── main_finetune.py
  │   └── main_metalens.py
  └── 功能:
      ├── 创建日志记录器
      ├── 彩色控制台输出
      └── 分布式训练支持
```

#### 模型层 (Model Layer)

```
model/vision_transformer.py
  ├── 依赖:
  │   ├── torch.nn
  │   └── timm.models (DropPath, trunc_normal_)
  ├── 被依赖:
  │   ├── model/simmim.py
  │   └── model/__init__.py
  └── 组件:
      ├── PatchEmbed (Jones矩阵 → Token序列)
      ├── Attention (多头自注意力)
      ├── Mlp (前馈网络)
      ├── Block (Transformer块)
      └── VisionTransformer (主模型)

model/simmim.py
  ├── 依赖:
  │   ├── torch.nn
  │   └── model/vision_transformer.py
  ├── 被依赖:
  │   └── model/__init__.py
  └── 组件:
      ├── VisionTransformerForSimMIM (带掩码的VIT)
      └── SimMIM (完整的MIM框架)

model/__init__.py
  ├── 依赖:
  │   ├── model/vision_transformer.py
  │   └── model/simmim.py
  ├── 被依赖:
  │   ├── main_pretrain.py
  │   ├── main_finetune.py
  │   └── main_metalens.py
  └── 功能:
      └── 统一模型构建接口 (build_model)
```

#### 数据层 (Data Layer)

```
data/data_simmim.py
  ├── 依赖:
  │   ├── torch.utils.data
  │   ├── numpy
  │   └── config
  ├── 被依赖:
  │   └── data/__init__.py
  └── 组件:
      ├── MaskGenerator (5种掩码策略)
      ├── MyDataSet (Jones矩阵数据集)
      └── build_loader_simmim (数据加载器)

data/data_finetune.py
  ├── 依赖:
  │   ├── torch.utils.data
  │   ├── numpy
  │   └── config
  ├── 被依赖:
  │   └── data/__init__.py
  └── 组件:
      ├── MyDataSet (微调数据集)
      └── build_loader_finetune (数据加载器)

data/data_recon.py
  ├── 依赖:
  │   ├── torch.utils.data
  │   ├── numpy
  │   └── config
  ├── 被依赖:
  │   └── data/__init__.py
  └── 组件:
      ├── MyDataSet (重建数据集)
      └── build_loader_recon (数据加载器)

data/__init__.py
  ├── 依赖:
  │   ├── data/data_simmim.py
  │   ├── data/data_finetune.py
  │   └── data/data_recon.py
  ├── 被依赖:
  │   ├── main_pretrain.py
  │   ├── main_finetune.py
  │   └── main_metalens.py
  └── 功能:
      └── 统一数据加载接口 (build_loader)
```

#### 训练优化层 (Training Optimization Layer)

```
optimizer.py
  ├── 依赖:
  │   ├── torch.optim
  │   └── config
  ├── 被依赖:
  │   ├── main_pretrain.py
  │   ├── main_finetune.py
  │   └── main_metalens.py
  └── 功能:
      ├── build_optimizer_pretrain (预训练优化器)
      └── build_optimizer_finetune (微调优化器，层级LR衰减)

lr_scheduler.py
  ├── 依赖:
  │   ├── timm.scheduler
  │   └── config
  ├── 被依赖:
  │   ├── main_pretrain.py
  │   ├── main_finetune.py
  │   └── main_metalens.py
  └── 功能:
      ├── CosineLRScheduler (余弦退火)
      ├── LinearLRScheduler (线性衰减)
      └── StepLRScheduler (步进衰减)

utils.py
  ├── 依赖:
  │   ├── torch
  │   ├── scipy.interpolate
  │   ├── apex (可选)
  │   └── config
  ├── 被依赖:
  │   ├── main_pretrain.py
  │   ├── main_finetune.py
  │   └── main_metalens.py
  └── 功能:
      ├── load_checkpoint (加载检查点)
      ├── save_checkpoint (保存检查点)
      ├── load_pretrained (加载预训练权重)
      ├── remap_pretrained_keys_vit (重映射权重)
      ├── auto_resume_helper (自动恢复)
      └── get_grad_norm (梯度范数)
```

---

## 数据流依赖关系

### 完整工作流程

```
┌─────────────────────────────────────────────────────────────┐
│                    Stage 1: 数据生成                         │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌────────────────────────────────────────────────────────┐
│ FDTD仿真 (Lumerical)                                   │
│  └── preprocess/FDTD_Simulation/unit_cell.py           │
└──────────────────┬─────────────────────────────────────┘
                   │ 输出: S参数
                   ▼
┌────────────────────────────────────────────────────────┐
│ Jones矩阵计算                                           │
│  └── preprocess/Jones_matrix_calculation/              │
│      ├── jones_matrix.py                               │
│      ├── jones_vector.py                               │
│      └── double_cell.py                                │
└──────────────────┬─────────────────────────────────────┘
                   │ 输出: Jones矩阵 + 结构参数
                   ▼
┌────────────────────────────────────────────────────────┐
│ 数据生成                                                │
│  └── preprocess/data_generation.py                     │
└──────────────────┬─────────────────────────────────────┘
                   │
                   ├──→ training_data_X/
                   │     ├── JM_train_X_Y.txt
                   │     └── para_train_X_Y.txt
                   │
                   └──→ finetune_data_X/
                         ├── JM_train_X.txt
                         └── para_train_X.txt

┌─────────────────────────────────────────────────────────────┐
│                    Stage 2: 预训练                           │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌────────────────────────────────────────────────────────┐
│ 数据加载 (data/data_simmim.py)                          │
│  ├── 读取: JM_train_X_Y.txt                            │
│  └── 应用: 5种掩码策略                                  │
└──────────────────┬─────────────────────────────────────┘
                   │ [B, 1, 20, 6] + mask
                   ▼
┌────────────────────────────────────────────────────────┐
│ SimMIM模型 (model/simmim.py)                            │
│  ├── 编码器: VisionTransformer                         │
│  │   ├── PatchEmbed: [B,1,20,6] → [B,20,512]          │
│  │   ├── Transformer: 12层                             │
│  │   └── 输出: [B,20,512]                              │
│  └── 解码器: 1×1 Conv                                  │
│      └── 输出: [B,1,20,6] (重建的JM)                   │
└──────────────────┬─────────────────────────────────────┘
                   │ 损失: L1(重建, 原始)
                   ▼
┌────────────────────────────────────────────────────────┐
│ 训练循环 (main_pretrain.py)                             │
│  ├── 优化器: AdamW + 层级LR衰减                         │
│  ├── 调度器: Cosine退火 + Warmup                        │
│  └── 混合精度: PyTorch AMP 或 Apex                      │
└──────────────────┬─────────────────────────────────────┘
                   │
                   ▼
              预训练权重.pth
              (output/metaVIT/ckpt_epoch_X.pth)

┌─────────────────────────────────────────────────────────────┐
│                    Stage 3: 超表面设计                        │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌────────────────────────────────────────────────────────┐
│ 设计目标Jones矩阵                                        │
│  └── evaluation/metasurface_design/                    │
│      ├── image_generator.py (生成目标图像)              │
│      └── JM_generator.py (生成目标JM)                   │
└──────────────────┬─────────────────────────────────────┘
                   │ 设计类型1-4
                   │  1: 全息图
                   │  2: 彩色打印
                   │  3: 复用
                   │  4: 金属透镜
                   ▼
            设计的Jones矩阵 + 掩码
            (evaluation/metasurface_design/)

┌─────────────────────────────────────────────────────────────┐
│                    Stage 4: Jones矩阵重建                     │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌────────────────────────────────────────────────────────┐
│ 加载预训练模型 (main_pretrain.py --recon)               │
│  └── 使用训练好的SimMIM重建被掩码的部分                  │
└──────────────────┬─────────────────────────────────────┘
                   │
                   ▼
            重建的完整Jones矩阵
            (evaluation/metasurface_design/reconJMs/)

┌─────────────────────────────────────────────────────────────┐
│                    Stage 5: 微调训练                          │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌────────────────────────────────────────────────────────┐
│ 数据加载 (data/data_finetune.py)                        │
│  ├── 输入X: Jones矩阵 [B,1,20,6]                        │
│  └── 标签Y: 结构参数 [B,6]                              │
└──────────────────┬─────────────────────────────────────┘
                   │
                   ▼
┌────────────────────────────────────────────────────────┐
│ 加载预训练权重 (utils.load_pretrained)                  │
│  ├── 移除 'encoder.' 前缀                               │
│  ├── 重映射位置编码                                     │
│  └── 添加回归头                                         │
└──────────────────┬─────────────────────────────────────┘
                   │
                   ▼
┌────────────────────────────────────────────────────────┐
│ 微调模型 (model/vision_transformer.py)                  │
│  ├── 特征提取: VisionTransformer                        │
│  │   └── 输出: [B,512]                                 │
│  └── 回归头: Linear(512, 6)                             │
│      └── 输出: [B,6] (预测的结构参数)                   │
└──────────────────┬─────────────────────────────────────┘
                   │ 损失: SmoothL1(预测, 真实)
                   ▼
┌────────────────────────────────────────────────────────┐
│ 训练循环 (main_finetune.py)                             │
│  ├── 优化器: AdamW + 层级LR衰减 (不冻结VIT参数)         │
│  ├── 调度器: Cosine退火                                 │
│  └── 所有层都训练，但不同层学习率不同                    │
└──────────────────┬─────────────────────────────────────┘
                   │
                   ▼
              微调权重.pth
              (finetune_output/metaVIT/ckpt_epoch_X.pth)

┌─────────────────────────────────────────────────────────────┐
│                    Stage 6: 参数预测                          │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌────────────────────────────────────────────────────────┐
│ 加载重建的Jones矩阵 (data/data_recon.py)                │
│  └── 从reconJMs/读取                                    │
└──────────────────┬─────────────────────────────────────┘
                   │
                   ▼
┌────────────────────────────────────────────────────────┐
│ 使用微调模型预测 (main_finetune.py --eval)              │
│  └── 输入: 重建的JM                                     │
│      输出: 预测的结构参数                                │
└──────────────────┬─────────────────────────────────────┘
                   │
                   ▼
            预测的结构参数
            (evaluation/metasurface_verification/predict_params/)

┌─────────────────────────────────────────────────────────────┐
│                    Stage 7: 前向验证                          │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌────────────────────────────────────────────────────────┐
│ 方法1: Predictor (evaluation/.../predictor.py)         │
│  ├── 训练前向网络: 参数 → JM                            │
│  │   ├── MLP 或 CNN                                    │
│  │   └── 损失: MSE(预测JM, 真实JM)                     │
│  └── 验证预测的参数                                     │
│                                                         │
│ 方法2: Matcher (evaluation/.../matcher.py)             │
│  └── 在数据库中匹配最接近的参数                         │
└─────────────────────────────────────────────────────────┘
                            │
                            ▼
                    验证结果与评估
```

---

## 关键依赖说明

### 1. 为什么微调时不冻结VIT参数？

在 `optimizer.py` 中的实现策略：

```python
# 微调时使用层级学习率衰减，而不是冻结参数
def build_optimizer_finetune(config, model, logger):
    layer_decay = config.TRAIN.LAYER_DECAY  # 默认1.0
    
    # 为每一层分配不同的学习率
    embedding: base_lr * (decay^12) ≈ base_lr * 0.56  # 如decay=0.9
    block_0:   base_lr * (decay^11) ≈ base_lr * 0.62
    block_1:   base_lr * (decay^10) ≈ base_lr * 0.69
    ...
    block_11:  base_lr * (decay^1)  ≈ base_lr * 0.9
    head:      base_lr * (decay^0)  = base_lr * 1.0   # 学习率最大
```

**优点**：
- ✅ 充分利用预训练知识
- ✅ 所有层都能适应新任务
- ✅ 灵活性好，可精细控制
- ✅ 性能通常优于冻结策略

**如果需要冻结**：
```python
# 在 main_finetune.py 的 main() 函数中添加
for name, param in model.named_parameters():
    if 'head' not in name:
        param.requires_grad = False
```

### 2. 掩码策略的选择

5种掩码策略的适用场景：

| 类型 | 策略 | 学习目标 | 适用场景 |
|-----|------|---------|---------|
| 0 | 随机1-5 | 全面学习 | 通用预训练 |
| 1 | 波长掩码 | 波长依赖 | 宽带设计 |
| 2 | 相位掩码 | 振幅-相位关系 | 相位调制 |
| 3 | 类型1+极化 | 特定极化波长依赖 | 单极化宽带 |
| 4 | 类型2+极化 | 特定极化振幅-相位 | 单极化相位 |
| 5 | 12/22掩码 | 主极化分量 | 对角偏振 |

### 3. 损失类型的选择

在 `model/simmim.py` 中的三种损失：

```python
if loss_type == 0:
    # 全局损失：整个Jones矩阵
    loss = L1(pred, target)
    
elif loss_type == 1:
    # 掩码部分损失：仅被掩码的位置
    loss = L1(pred[mask], target[mask])
    
elif loss_type == 2:
    # 非掩码部分损失：仅未被掩码的位置
    loss = L1(pred[~mask], target[~mask])
```

**推荐配置**：
- 预训练：使用 `loss_type=1`（仅重建被掩码部分）
- 微调：使用 `SmoothL1Loss`（对异常值更鲁棒）

---

## 常见问题

### Q1: 如何选择合适的掩码类型？
**A**: 根据应用选择：
- 宽带设计 → 类型1或3
- 相位调制 → 类型2或4
- 通用场景 → 类型0（随机）

### Q2: 预训练需要多少数据？
**A**: 
- 小规模测试：~1M样本（训练几小时）
- 正式训练：~20M样本（推荐）
- 数据越多，预训练效果越好

### Q3: 微调数据集应该多大？
**A**:
- 大数据集（>10K）：全部训练，layer_decay=1.0
- 中等（1K-10K）：全部训练，layer_decay=0.65
- 小数据集（<1K）：考虑冻结底层

### Q4: 如何处理内存不足？
**A**:
```bash
# 方法1：减小批次大小
--batch_size 32

# 方法2：使用梯度累积
--batch_size 32 --accumulation_steps 4  # 等效batch=128

# 方法3：使用混合精度
--amp_type pytorch

# 方法4：使用梯度检查点
--use_checkpoint
```

### Q5: 分布式训练如何配置？
**A**:
```bash
# 4 GPU训练
python -m torch.distributed.launch \
    --nproc_per_node 4 \
    main_pretrain.py \
    --batch_size 128  # 每个GPU的批次
```

---

## 性能优化建议

### GPU内存优化
1. **混合精度训练**: 节省~50%内存
   ```bash
   --amp_type pytorch --amp_opt_level O1
   ```

2. **梯度累积**: 小batch模拟大batch
   ```bash
   --batch_size 32 --accumulation_steps 4
   ```

3. **梯度检查点**: 节省内存但增加计算
   ```bash
   --use_checkpoint
   ```

### 训练速度优化
1. **多GPU训练**: 线性加速
   ```bash
   python -m torch.distributed.launch --nproc_per_node 4
   ```

2. **数据加载**: 增加worker数量
   ```python
   DATA.NUM_WORKERS = 8  # 在config.py中设置
   ```

3. **cuDNN优化**: 自动选择最优算法
   ```python
   cudnn.benchmark = True  # 已在main程序中启用
   ```

---

## 总结

MetasurfaceVIT项目的依赖关系清晰且模块化：

1. **配置层**：统一管理所有参数
2. **数据层**：灵活的数据加载和掩码策略
3. **模型层**：模块化的Transformer架构
4. **优化层**：高级训练技巧（层级LR、混合精度）
5. **主程序**：完整的训练和评估流程

所有核心模块都已添加详细的中文注释，便于理解和扩展。

---

**文档版本**: v1.0  
**更新日期**: 2025-11-05  
**维护者**: MetasurfaceVIT Team
